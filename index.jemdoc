= Harsh Panchal

~~~
{}{img_left}{harsh_panchal.jpg}{Image of Harsh Panchal}{200px}{200px}

I am a software engineer currently working at Facebook with the Identity Platform team, building infrastructure and frameworks that help scale the platform better.

Prior to that, I was working at [https://www.thumbtack.com/ Thumbtack], focusing mainly on backend infrastructure for the marketplace matching team, helping them support higher query loads at lower latencies.

Before Thumbtack, I was working at Oracle in the [https://docs.oracle.com/cd/E11882_01/server.112/e18951/asmcon.htm Automatic Storage Management] team.

I completed my Masters in Computer Science from [https://www.cornell.edu/ Cornell University] in 2013.

My expertise and interests include building scalable infrastructure and software solutions for various domains including machine learning and search retrieval.\n\n

[https://www.linkedin.com/in/panchalhp /LinkedIn/]   |   [https://github.com/panchalhp /GitHub/]   |   [harsh_panchal_resume.pdf /Resume/] \n
*Email*: [panchalhp@gmail.com panchalhp@gmail.com]

~~~

== Skills and Experience
- *Programming Languages*: Hack/PHP, Go, Python, Scala, C\+\+, Java
- *Datastores*: PostgreSQL, Elasticsearch, DynamoDB
- *Frameworks*: Spark, Play, Akka
- *Amazon Web Services*: Simple Queing Service, DynamoDB, S3
- *Google Cloud Platform*: Dataproc, BigQuery, Google Cloud Storage
- *Tools*: Git, Intellij, Vim

== Work Experience
=== Facebook (Mar 2019 - Present)
- *Building framework to support privacy enforcement at scale*
-- Working on tagging data sources and propagating relevant metadata across various pipelines to allow serving of privacy compliant identity data to various internal customers


- *Modularizing model versioning framework for Identity Platform*
-- Abstracted common transformations across 10s of model versions into config files which were injected into data pipelines to allow model developers to iterate faster
-- Collaborated across multiple teams to better understand the gaps in the existing framework and provide the support and framework improvements they would need to execute faster on their roadmap
-- Better modularization allowed developers to support numerous privacy compliant model versions in a tight timeframe which would otherwise take 3x the number of resources


=== Thumbtack (Nov 2015 - Mar 2019)
- *Reducing latency of search results*
-- Reduced e2e latency of the service that searches and ranks professionals using a customer request by 33% at the 95th percentile
-- Added better instrumentation (metrics and traces) to gain deeper insight into slow components in the service
-- Rearchitected the matching service by enforcing a modularized structure and restricting all external I/O calls to only the data enrichment module where independent network calls are always made in parallel
-- Optimized the datastore performance by reducing the data size by 70% making it more efficient
-- Increased the availability of the service by making certain dependencies non-critical to ensure that requests are served (albeit with a performance degradation) even when other dependent components are down


- *Aggregated click signal data to use in ranking search results*
-- Built an offline pipeline that synthesizes relevant events data to extract signals about the customer's engagement with Thumbtack's [https://www.thumbtack.com/ca/san-francisco/house-cleaning/ search results] (views, clicks, contacts etc.) and made it available for offline analysis and online serving
-- Built the scalable pipeline using /Scala + Spark/ which generates daily snapshots by aggregating data over the past few months
-- Optimized the pipeline to calculate daily snapshots in less than 10 minutes despite having about 65 million events per day to process
-- Added monitoring dashboards and alerting to validate the generated data to ensure sanity and to make it immune to upstream changes

- *Building Thumbtack's machine learning platform*
-- Part of a 2 people team that built the entire of Thumbtack's machine learning infrastructure from the ground up
-- Infrastructure was built using /Scala + Spark/, leveraging Spark's MLLib library
-- Machine learning platform supported the following features:
--- Model deployment and online serving
--- Model retraining pipeline
--- Automated model evaluation after retraining
--- Automated dark launching of the new retrained model
--- Logging pipeline for the online predictions to track online model performance
--- Comparing online performance of dark launched model with the existing model
--- Built a feature store to make it easier for data scientists to mix and match and re-use existing / pre-calculated features
-- The platform supported 10+ models serving production traffic including linear and logistic regression models, naive bayes, random forest and gradient boosted trees which powered some of Thumbtack's core product experiences

=== Oracle (Jul 2013 - Nov 2015)
- *Version compatibility between Oracle RDBMS and ASM*
-- Developed a framework to identify the compatibility between different versions of Oracle' Automatic Storage Manager (ASM) and Oracle's Relational Database Management System (RDBMS) by checking the information about the various dependent patch-set units applied to both components at startup


